{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9/10주차 과제.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd \n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import re\n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "FFOMQqje5r1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test code \n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "text = \"아 나는 역시 밤에 일이 잘된다.\"\n",
        "\n",
        "print(okt.morphs(text, stem=True))"
      ],
      "metadata": {
        "id": "ejWGVIwf54Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pres=['https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=161967&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=highest&page=1',\n",
        "'https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=161967&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=lowest&page=1']"
      ],
      "metadata": {
        "id": "ICBTni6H58XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터양 \n",
        "\n",
        "review = []\n",
        "rate =[]\n",
        "target=[]\n",
        "\n",
        "for pre in pres:\n",
        "    for i in range(1,200):\n",
        "        url=pre+str(i)\n",
        "        res=requests.get(url)\n",
        "        soup=BeautifulSoup(res.content,'html.parser')\n",
        "        \n",
        "        id_list=[]\n",
        "        id_pre='_filtered_ment_'\n",
        "        \n",
        "        for i in range(10):\n",
        "            id_list.append(id_pre+str(i))\n",
        "        \n",
        "        for id in id_list:\n",
        "            review.append(soup.find('span',{'id':id}).get_text().strip())\n",
        "            \n",
        "        rate_list =[]\n",
        "        rate_list =(soup.select('div.star_score > em'))\n",
        "        \n",
        "        for i in range(10):\n",
        "            r = int(re.sub('<.+?>','',str(rate_list[i])))\n",
        "            rate.append(r)\n",
        "            if r>=8:\n",
        "                target.append(1)\n",
        "            elif r<=4:\n",
        "                target.append(0)\n",
        "            else:\n",
        "                target.append(-1)\n",
        "        \n",
        "\n",
        "df=pd.DataFrame({'review':review,'rate':rate,'target':target})\n",
        "df"
      ],
      "metadata": {
        "id": "CakUiHQB6GqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rate.unique()"
      ],
      "metadata": {
        "id": "3d8jSH-W6F3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x,test_x,train_y,test_y=train_test_split(review,target,test_size=0.2,random_state=0)\n",
        "\n",
        "len(train_x),len(train_y)\n",
        "len(test_x),len(test_y)"
      ],
      "metadata": {
        "id": "xMUXvmnK6MXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텍스트 데이터의 백터화\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "okt=Okt()\n",
        "\n",
        "tfv = TfidfVectorizer(tokenizer=okt.morphs,ngram_range=(1,2),min_df=3,max_df=0.9)\n",
        "tfv.fit(train_x)\n",
        "\n",
        "tfv_train_x = tfv.transform(train_x)\n",
        "tfv_train_x\n"
      ],
      "metadata": {
        "id": "dMbsrjk46P8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#로지스틱 회귀 모형으로 모델 적합 \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.experimental import enable_halving_search_cv \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = LogisticRegression(random_state=0)\n",
        "params = {'C':[1,3,5,7,9]}\n",
        "grid_cv = GridSearchCV(clf,param_grid=params,cv=4,scoring=\"accuracy\",verbose=1)\n",
        "grid_cv.fit(tfv_train_x,train_y)"
      ],
      "metadata": {
        "id": "iLbzdUHz6YeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터를 통한 예측 정확도 산출 \n",
        "tfv_test_x=tfv.transform(test_x)\n",
        "grid_cv.best_estimator_.score(tfv_test_x,test_y)"
      ],
      "metadata": {
        "id": "H5RapUmg6aHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#영화 리뷰에 대한 긍부정 분류 \n",
        "my_review = tfv.transform([input()])\n",
        "if(grid_cv.best_estimator_.predict(my_review)):\n",
        "    print(\"긍정 리뷰\")\n",
        "else:\n",
        "    print(\"부정 리뷰\")"
      ],
      "metadata": {
        "id": "Hl9hLsho6agv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "W43zZi3-6cIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "word_list = df[\"review\"]"
      ],
      "metadata": {
        "id": "xqOq4bPt6eYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#형태소 분리 \n",
        "sentences_tag = []\n",
        "\n",
        "for sentence in word_list: \n",
        "    morph = okt.pos(sentence)\n",
        "    sentences_tag.append(morph)"
      ],
      "metadata": {
        "id": "_pMZaKW76tDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_tag"
      ],
      "metadata": {
        "id": "y2X_ZD1lCSJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#명사만 추출 \n",
        "noun_list = [] \n",
        "for sentence in sentences_tag:\n",
        "    for word, tag in sentence:\n",
        "        if tag in [\"Noun\"]:\n",
        "            noun_list.append(word)"
      ],
      "metadata": {
        "id": "4wZVd-Ec6ywA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noun_list"
      ],
      "metadata": {
        "id": "p_1MWKN6Ck7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(noun_list)\n",
        "#글자 길이가 1인것은 제외 \n",
        "noun_list = [n for n in noun_list if len(n)>1] \n",
        "noun_list[:80]"
      ],
      "metadata": {
        "id": "yOIw93PNCtHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#단어별 갯수 세기 \n",
        "counts = Counter(noun_list)\n",
        "tags = counts.most_common(40)\n",
        "tags"
      ],
      "metadata": {
        "id": "ElkLdXigCtJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#불필요한 단어 삭제\n",
        "tags.remove(('그냥',119))\n",
        "tags.remove(('보고',199))\n",
        "tags.remove(('영화',2075))\n",
        "tags.remove(('하나',89))"
      ],
      "metadata": {
        "id": "tEFQnvIeCtNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib import request\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "sc7JGIFxLxZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()\n",
        "!ls"
      ],
      "metadata": {
        "id": "mnRq4HSUXumF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#워드클라우드 마스크 이미지 설정 \n",
        "mask = np.array(Image.open(\"person_a.png\"))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(mask)\n",
        "plt.axis('off')\n",
        "plt.show \n",
        "\n",
        "from wordcloud import  ImageColorGenerator\n",
        "image_colors = ImageColorGenerator(mask)"
      ],
      "metadata": {
        "id": "jBFno4PQLjUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#워드클라우드 만들기/폰트 설정\n",
        "from wordcloud import WordCloud "
      ],
      "metadata": {
        "id": "o2puzkpoSZ-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font_path = '/usr/share/fonts/truetype/nanum/NanumMyeongjoBold.ttf'\n",
        "wc =WordCloud(font_path=font_path, background_color='white', width=800, height=600, mask=mask)\n",
        "cloud = wc.generate_from_frequencies(dict(tags))\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(cloud)"
      ],
      "metadata": {
        "id": "LDXwFpXVZLrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd \n",
        "from math import log \n",
        "docs = noun_list[:80]\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()"
      ],
      "metadata": {
        "id": "7N6-t_ykWG2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(docs) # 총 문서의 수\n",
        "\n",
        "def tf(t, d):\n",
        "    return d.count(t)\n",
        "\n",
        "def idf(t):\n",
        "    df = 0\n",
        "    for doc in docs:\n",
        "        df += t in doc\n",
        "    return log(N/(df + 1))\n",
        "\n",
        "def tfidf(t, d):\n",
        "    return tf(t,d)*idf(t)"
      ],
      "metadata": {
        "id": "cSpCV8Q8WGvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(N): # 각 문서에 대해서 아래 명령을 수행\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]\n",
        "        result[-1].append(tf(t,d))\n",
        "\n",
        "tf_ = pd.DataFrame(result, columns = vocab)\n",
        "tf_"
      ],
      "metadata": {
        "id": "DPdzXTk7bbcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result =[]\n",
        "for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result.append(idf(t))\n",
        "\n",
        "idf_= pd.DataFrame(result, index = vocab,columns = [\"IDF\"])\n",
        "idf_"
      ],
      "metadata": {
        "id": "oPsp5XU9e25I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(N):\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]\n",
        "\n",
        "        result[-1].append(tfidf(t,d))\n",
        "\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "tfidf_"
      ],
      "metadata": {
        "id": "W7X0y9DbbbS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최빈단어와는 다른 종류의 단어들이 나왔다 최빈 단어에서는 최빈단어는 빈도수만을 가지고 파악하기 때문에 의미 없는 단어에 높은 수치를 부여할 수 있다 즉 중요한 단어는 몇번 잘 등장하지 않지만 너무 적게 들어나오지도 않는다tfidf_를 통해서 적절하게 출현한 단어들에 가중치를 주어 분석해본 결과 끝맛, 가족, 가난, 머리, 모험물과 같은 단어가 나오는 것을 보며 중요단어들을 새롭게 파악이 가능했다\n",
        "\n"
      ],
      "metadata": {
        "id": "9TwceAWzjbwz"
      }
    }
  ]
}